{"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install lightning\n!pip install torch","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:35:18.818316Z","iopub.execute_input":"2024-09-21T13:35:18.818885Z","iopub.status.idle":"2024-09-21T13:35:50.678082Z","shell.execute_reply.started":"2024-09-21T13:35:18.818829Z","shell.execute_reply":"2024-09-21T13:35:50.676472Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting lightning\n  Downloading lightning-2.4.0-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: PyYAML<8.0,>=5.4 in /opt/conda/lib/python3.10/site-packages (from lightning) (6.0.2)\nRequirement already satisfied: fsspec<2026.0,>=2022.5.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (2024.6.1)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (0.11.6)\nRequirement already satisfied: packaging<25.0,>=20.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (21.3)\nRequirement already satisfied: torch<4.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (2.4.0+cpu)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (1.4.1)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.66.4)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /opt/conda/lib/python3.10/site-packages (from lightning) (4.12.2)\nRequirement already satisfied: pytorch-lightning in /opt/conda/lib/python3.10/site-packages (from lightning) (2.4.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning) (3.9.5)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities<2.0,>=0.10.0->lightning) (70.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging<25.0,>=20.0->lightning) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<4.0,>=2.1.0->lightning) (3.1.4)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics<3.0,>=0.7.0->lightning) (1.26.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (4.0.3)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<4.0,>=2.1.0->lightning) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<4.0,>=2.1.0->lightning) (1.3.0)\nRequirement already satisfied: idna>=2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning) (3.7)\nDownloading lightning-2.4.0-py3-none-any.whl (810 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m811.0/811.0 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: lightning\nSuccessfully installed lightning-2.4.0\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as functional\nfrom torch.optim import Adam\nfrom torch.utils.data import TensorDataset, DataLoader\nimport lightning","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-09-21T13:35:50.681486Z","iopub.execute_input":"2024-09-21T13:35:50.682046Z","iopub.status.idle":"2024-09-21T13:35:58.304760Z","shell.execute_reply.started":"2024-09-21T13:35:50.681990Z","shell.execute_reply":"2024-09-21T13:35:58.303239Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"There are only two prompts we want our transformer to respond to:-\n\n\"What is PyTorch?\" and \"PyTorch is what?\"\n\nThe answer for both of these would be: \"Awesome\"","metadata":{}},{"cell_type":"code","source":"# Vocabulary - Our world only knows 5 tokens!\ntoken_to_id = {\"what\": 0, \"is\": 1, \"pytorch\": 2, \"awesome\": 3, \"<EOS>\": 4}\nid_to_token = dict(map(reversed, token_to_id.items()))\n\nprint(f\"{token_to_id=} \\n{id_to_token=}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:35:58.306874Z","iopub.execute_input":"2024-09-21T13:35:58.308122Z","iopub.status.idle":"2024-09-21T13:35:58.316375Z","shell.execute_reply.started":"2024-09-21T13:35:58.308045Z","shell.execute_reply":"2024-09-21T13:35:58.314672Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"token_to_id={'what': 0, 'is': 1, 'pytorch': 2, 'awesome': 3, '<EOS>': 4} \nid_to_token={0: 'what', 1: 'is', 2: 'pytorch', 3: 'awesome', 4: '<EOS>'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# We have 2 sentences, so inputs will be those token_to_id in order\ninputs = torch.tensor([\n    [\n        token_to_id[\"what\"],\n        token_to_id[\"is\"],\n        token_to_id[\"pytorch\"],\n        token_to_id[\"<EOS>\"],\n        token_to_id[\"awesome\"]\n    ],\n    [\n        token_to_id[\"pytorch\"],\n        token_to_id[\"is\"],\n        token_to_id[\"what\"],\n        token_to_id[\"<EOS>\"],\n        token_to_id[\"awesome\"]\n    ]\n])\n\n# Each input token's next token to be predicted is below. \n# For the first sentence, we want the decoder to output \"is\" for the input \"what\". \n# For the next token \"is\", we want the decoder to output \"pytorch\" and so on...\nlabels = torch.tensor([\n    [\n        token_to_id[\"is\"],\n        token_to_id[\"pytorch\"],\n        token_to_id[\"<EOS>\"],\n        token_to_id[\"awesome\"],\n        token_to_id[\"<EOS>\"]\n    ],\n    [\n        token_to_id[\"is\"],\n        token_to_id[\"what\"],\n        token_to_id[\"<EOS>\"],\n        token_to_id[\"awesome\"],\n        token_to_id[\"<EOS>\"]\n    ]\n])\n\ndataset = TensorDataset(inputs, labels)\ndataloader = DataLoader(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:35:58.319931Z","iopub.execute_input":"2024-09-21T13:35:58.320453Z","iopub.status.idle":"2024-09-21T13:35:58.350912Z","shell.execute_reply.started":"2024-09-21T13:35:58.320411Z","shell.execute_reply":"2024-09-21T13:35:58.349403Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Now Positional Encoding!\n\nclass PositionEncoding(nn.Module):\n    def __init__(self, d_model=2, max_len=6):\n        # d_model - dimension of model, no. of word embedding values per token - 2.\n        # max_len is max no. of tokens that our transformer can process - 6 \n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        \n        position = torch.arange(start=0, end=max_len, step=1).float().unsqueeze(1)\n        embedding_index = torch.arange(start=0, end=d_model, step=2).float()\n        \n        div_term = 1/torch.tensor(10000.0)**(embedding_index / d_model)\n        \n        # PE(pos, 2i) = sin(pos/10000^(2i/d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        \n        # PE(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n        pe[:, 1::2] = torch.cos(position * div_term)\n        \n        \n        self.register_buffer('pe', pe)\n        \n    def forward(self, word_embeddings):\n        # add positional encodings to word embeddings\n        return word_embeddings + self.pe[:word_embeddings.size(0), :]","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:35:58.352424Z","iopub.execute_input":"2024-09-21T13:35:58.352833Z","iopub.status.idle":"2024-09-21T13:35:58.363019Z","shell.execute_reply.started":"2024-09-21T13:35:58.352792Z","shell.execute_reply":"2024-09-21T13:35:58.361645Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Masked Self Attention\nclass Attention(nn.Module):\n    def __init__(self, d_model=2):\n        super().__init__()\n        \n        # in - rows in weight matrix\n        # out - cols in output \n        # this returns untrained objects and also does training later on \n        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False) # query\n        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False) # key\n        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False) # values\n        \n        self.row_dim = 0\n        self.col_dim = 1\n    \n    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n        q = self.W_q(encodings_for_q)\n        k = self.W_k(encodings_for_k)\n        v = self.W_v(encodings_for_v)\n        \n        # Attention(Q,K,V) = softmax(((QK^T)/(dk)^(1/2)) + M) * V\n        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n        scaled_sims = sims / torch.tensor(k.size(self.col_dim) ** 0.5)\n        \n        if mask is not None:\n            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n        \n        attention_percents = functional.softmax(scaled_sims, dim=self.col_dim)\n        attention_scores = torch.matmul(attention_percents, v)\n        \n        return attention_scores","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:35:58.364724Z","iopub.execute_input":"2024-09-21T13:35:58.365513Z","iopub.status.idle":"2024-09-21T13:35:58.386044Z","shell.execute_reply.started":"2024-09-21T13:35:58.365446Z","shell.execute_reply":"2024-09-21T13:35:58.384635Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Putting them together\nclass DecoderOnlyTransformer(lightning.LightningModule):\n    def __init__(self, num_tokens=4, d_model=2, max_len=6):\n        super().__init__()\n        \n        self.we = nn.Embedding(num_embeddings=num_tokens, embedding_dim=d_model)\n        self.pe = PositionEncoding(d_model=d_model, max_len=max_len)\n        self.self_attention = Attention(d_model=d_model)\n        self.fc_layer = nn.Linear(in_features=d_model, out_features=num_tokens)\n        \n        self.loss = nn.CrossEntropyLoss() # does softmax too\n        \n    def forward(self, token_ids):\n        word_embeddings = self.we(token_ids)\n        position_encoded = self.pe(word_embeddings)\n        \n        mask = torch.tril(torch.ones((token_ids.size(dim=0), token_ids.size(dim=0))))\n        mask = mask == 0\n        \n        self_attention_values = self.self_attention(position_encoded, position_encoded, position_encoded, mask=mask)\n        \n        residual_connection_values = position_encoded + self_attention_values\n        fc_layer_output = self.fc_layer(residual_connection_values)\n        return fc_layer_output\n    \n    def configure_optimizers(self):\n        return Adam(self.parameters(), lr=0.1)\n    \n    def training_step(self, batch, batch_idx):\n        input_tokens, labels = batch\n        output = self.forward(input_tokens[0])\n        loss = self.loss(output, labels[0])\n        \n        return loss","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:35:58.387713Z","iopub.execute_input":"2024-09-21T13:35:58.388111Z","iopub.status.idle":"2024-09-21T13:35:58.406920Z","shell.execute_reply.started":"2024-09-21T13:35:58.388072Z","shell.execute_reply":"2024-09-21T13:35:58.405443Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = DecoderOnlyTransformer(num_tokens=len(token_to_id), d_model=2, max_len=6)\n\nmodel_input = torch.tensor([\n    token_to_id[\"what\"],\n    token_to_id[\"is\"],\n    token_to_id[\"pytorch\"],\n    token_to_id[\"<EOS>\"]\n])\n\ninput_length = model_input.size(dim=0)\n\npredictions = model(model_input)\npredicted_id = torch.tensor([torch.argmax(predictions[-1,:])]) # After EOS. Taking largest value\npredicted_ids = predicted_id\n\nmax_length = 6\nfor i in range(input_length, max_length):\n    if (predicted_id == token_to_id[\"<EOS>\"]):\n        break\n    \n    model_input = torch.cat((model_input, predicted_id))\n    \n    predictions = model(model_input)\n    predicted_id = torch.tensor([torch.argmax(predictions[-1:])])\n    predicted_ids = torch.cat((predicted_ids, predicted_id))\n\nprint(\"Predicted Tokens:\\n\")\nfor id_ in predicted_ids:\n    print(\"\\t\", id_to_token[id_.item()])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:35:58.408487Z","iopub.execute_input":"2024-09-21T13:35:58.408885Z","iopub.status.idle":"2024-09-21T13:35:58.583588Z","shell.execute_reply.started":"2024-09-21T13:35:58.408846Z","shell.execute_reply":"2024-09-21T13:35:58.582100Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Predicted Tokens:\n\n\t what\n\t awesome\n\t what\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = lightning.Trainer(max_epochs=30)\ntrainer.fit(model, train_dataloaders=dataloader)","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:35:58.585065Z","iopub.execute_input":"2024-09-21T13:35:58.585456Z","iopub.status.idle":"2024-09-21T13:36:16.687082Z","shell.execute_reply.started":"2024-09-21T13:35:58.585416Z","shell.execute_reply":"2024-09-21T13:36:16.684421Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"INFO: GPU available: False, used: False\nINFO: TPU available: False, using: 0 TPU cores\nINFO: HPU available: False, using: 0 HPUs\nINFO: \n  | Name           | Type             | Params | Mode \n------------------------------------------------------------\n0 | we             | Embedding        | 10     | train\n1 | pe             | PositionEncoding | 0      | train\n2 | self_attention | Attention        | 12     | train\n3 | fc_layer       | Linear           | 15     | train\n4 | loss           | CrossEntropyLoss | 0      | train\n------------------------------------------------------------\n37        Trainable params\n0         Non-trainable params\n37        Total params\n0.000     Total estimated model params size (MB)\n8         Modules in train mode\n0         Modules in eval mode\n/opt/conda/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/opt/conda/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:298: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"179c48525ee74b2f924f5781c5a5e379"}},"metadata":{}},{"name":"stderr","text":"INFO: `Trainer.fit` stopped: `max_epochs=30` reached.\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = DecoderOnlyTransformer(num_tokens=len(token_to_id), d_model=2, max_len=6)\n# We are using the trained model now!!!\n\nmodel_input = torch.tensor([\n    token_to_id[\"what\"],\n    token_to_id[\"is\"],\n    token_to_id[\"pytorch\"],\n    token_to_id[\"<EOS>\"]\n])\n\ninput_length = model_input.size(dim=0)\n\npredictions = model(model_input)\npredicted_id = torch.tensor([torch.argmax(predictions[-1,:])]) # After EOS. Taking largest value\npredicted_ids = predicted_id\n\nmax_length = 6\nfor i in range(input_length, max_length):\n    if (predicted_id == token_to_id[\"<EOS>\"]):\n        break\n    \n    model_input = torch.cat((model_input, predicted_id))\n    \n    predictions = model(model_input)\n    predicted_id = torch.tensor([torch.argmax(predictions[-1:])])\n    predicted_ids = torch.cat((predicted_ids, predicted_id))\n\nprint(\"Predicted Tokens:\\n\")\nfor id_ in predicted_ids:\n    print(\"\\t\", id_to_token[id_.item()])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:36:16.691965Z","iopub.execute_input":"2024-09-21T13:36:16.692859Z","iopub.status.idle":"2024-09-21T13:36:16.709742Z","shell.execute_reply.started":"2024-09-21T13:36:16.692805Z","shell.execute_reply":"2024-09-21T13:36:16.707874Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Predicted Tokens:\n\n\t awesome\n\t <EOS>\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = DecoderOnlyTransformer(num_tokens=len(token_to_id), d_model=2, max_len=6)\n# We are using the trained model now!!!\n\nmodel_input = torch.tensor([\n    token_to_id[\"pytorch\"],\n    token_to_id[\"is\"],\n    token_to_id[\"what\"],\n    token_to_id[\"<EOS>\"]\n])\n\ninput_length = model_input.size(dim=0)\n\npredictions = model(model_input)\npredicted_id = torch.tensor([torch.argmax(predictions[-1,:])]) # After EOS. Taking largest value\npredicted_ids = predicted_id\n\nmax_length = 6\nfor i in range(input_length, max_length):\n    if (predicted_id == token_to_id[\"<EOS>\"]):\n        break\n    \n    model_input = torch.cat((model_input, predicted_id))\n    \n    predictions = model(model_input)\n    predicted_id = torch.tensor([torch.argmax(predictions[-1:])])\n    predicted_ids = torch.cat((predicted_ids, predicted_id))\n\nprint(\"Predicted Tokens:\\n\")\nfor id_ in predicted_ids:\n    print(\"\\t\", id_to_token[id_.item()])","metadata":{"execution":{"iopub.status.busy":"2024-09-21T13:36:16.712175Z","iopub.execute_input":"2024-09-21T13:36:16.713494Z","iopub.status.idle":"2024-09-21T13:36:16.747024Z","shell.execute_reply.started":"2024-09-21T13:36:16.713411Z","shell.execute_reply":"2024-09-21T13:36:16.745523Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Predicted Tokens:\n\n\t awesome\n\t <EOS>\n","output_type":"stream"}]}]}